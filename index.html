<!doctype html>
<html lang="en">
<head>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css">


    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Immersive Tech Researcher">
    <meta name="author" content="Eugy Han">
    <meta name="theme-color" content="#222222">

    <link rel="apple-touch-icon" sizes="180x180" href="images/nicons/favicon.ico">
    <link rel="icon" type="image/png" sizes="32x32" href="images/nicons/favicon.ico">
    <link rel="icon" type="image/png" sizes="16x16" href="images/nicons/favicon.ico">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <link rel="stylesheet" href="assets/style-3.css">

    <title>Eugy Han</title>
</head>
<body>


    <!-- <h1>Hello, world!</h1> -->
    <div class="container pt-5 allstuffp">
        <div class="row pt-5 allstuff">
            <div class="col-md-3 pt-5">
                <div class="fixed-posi">
                    <!-- <p class="name">Eugy Han</p> -->
                    <img src="images/profile.jpg" class="profilepic pt-3 pb-2">
                    <div class="pt-5 menur"><a class="menulink" target="_blank" href="https://drive.google.com/file/d/1hMepIACGgwjb-UV59gIHSYwf6WtlUdJK/view?usp=drive_link">curriculum vitae</a></div>
                    <div class=""><a class="menulink" target="_blank" href="https://scholar.google.com/citations?user=V68DTy8AAAAJ&hl=en">google scholar</a></div>
                    <div class=""><a class="menulink" target="_blank" href="mailto:eugyoung.han@ufl.edu">email</a></div>


                    <!-- <div class="pt-5">usercontext</div> -->
                    <!-- <div class="">travel history</div> -->
                    <!-- <div class="">this template</div> -->
                </div>
            </div>
            <div class="col-md-9 pt-5 about">
                Hi, my name is Eugy [pronounced like boo üëª - geese ü™ø but without the "b-" and "-se"]. I am an incoming Assistant Professor in the <a class="in-text" href="https://www.jou.ufl.edu/mpmt/" target="_blank">Department of Media Production, Management, and Technology</a> (in the College of Journalism & Communication) at the University of Florida. I received my Ph.D. in Communication (Media Psychology) in 2025 from Stanford University, where I was advised by Professor Jeremy N. Bailenson at the Virtual Human Interaction Lab. Before Stanford, I earned my B.S. in Cognitive Science in 2020 from Brown University, where I was advised by Professor William H. Warren at the Virtual Environment Navigation Lab<br><br>

                My research focuses on understanding what social interactions look like in immersive virtual environments, such as virtual and mixed reality. Specifically, I investigate how contextual factors ‚Äî physical, virtual, and social ‚Äî influence these interactions. I conduct large-scale, longitudinal studies to understand outcomes such as nonverbal behaviors and psychological processes. My work related to this has been covered by <a class="in-text" href="https://venturebeat.com/games/vr-study-shows-virtual-avatars-and-environments-can-affect-your-mood/" target="_blank">VentureBeat</a> and <a class="in-text" href="https://news.stanford.edu/stories/2022/12/vr-real-impact-study-finds" target="_blank">Stanford News</a>.<br><br>

                Another thread of my research focuses on how we can integrate immersive technologies in sustainable and equitable ways into education. My work related to this has been covered by <a class="in-text" href="https://www.cnn.com/2022/01/27/tech/vr-classes/index.html" target="_blank">CNN</a> and <a class="in-text" href="https://news.stanford.edu/stories/2021/11/new-class-among-first-taught-entirely-virtual-reality" target="_blank">Stanford News</a>.

                <p class="header pt-5">What's Going On...</p>
                <div class="py-2">
                 <p class="paper my-2 pl-2">
                     <span class="papertitle">Joining UF in the Fall! üêä</span><br>
                     I'll be joining the <a class="in-text" href="https://www.jou.ufl.edu/mpmt/" target="_blank">Department of Media Production, Management, and Technology (MPMT)</a> in the College of Journalism and Communications (CJC) at the University of Florida starting Fall 2025.
                 </p>
                 <!-- Include another whole div class py-2 if you want more space between each item -->
                 <p class="paper my-2 pl-2">
                     <span class="papertitle">See you at AWE 2025 üëì</span><br>
                     I'll be speaking at the Augmented World Expo (AWE) on a <a class="in-text" href="https://awexr.com/usa-2025/agenda/1156" target="_blank">panel</a> on "AI NPCs in Embodied Forums: Humans & NPCs in Social, Education and Business 3D Worlds."
                 </p>

                 <p class="header pt-5">Selected Publications</p>
                 Below are my <b>highlighted</b> works. You can also read my full <a class="in-text" href="https://drive.google.com/file/d/1hMepIACGgwjb-UV59gIHSYwf6WtlUdJK/view?usp=drive_link" target="_blank">CV</a>, which includes a full list of publications, including journal articles, conference proceedings, non-archival conference papers/posters, and book chapters.

                 
                 <div class="py-2">
                    <p class="paper my-2 pl-2">
                     <span class="papertitle">Five canonical findings from 30 years of psychological experimentation in virtual reality</span><br>
                     Jeremy N. Bailenson, Cyan DeVeaux, <span class="thisauthor">Eugy Han</span>, Monique Santoso, and Portia Wang<br>
                     <i>Nature Human Behavior</i>, 2025<br>
                     <a class="tag" href="assets/pdfs/bailenson-nhb-2025.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
                     <a class="tag" href="https://www.nature.com/articles/s41562-025-02216-3" target="_blank">website</a><span class="tagsep">|</span>
                     <a class="tag" href="https://news.stanford.edu/stories/2025/05/how-to-use-virtual-reality-experimental-research" target="_blank">news coverage</a><span class="tagsep">|</span>
                     <a class="tag toggle-abstract" href="javascript:void(0);">nutshell description</a>
                 </p>

                 <div class="abstract-content">
                    <p>This review article presents five canonical psychological research findings in VR over the past three decades: (1) the benefit of being there depends on the activity, (2) self-avatars influence behavior, (3) procedural training works better than abstract learning, (4) body tracking makes VR unique, (5) people underestimate distance in VR. We provide recommendations for both researchers and users of VR.</p>
                </div>


                <br> 

                     <p class="paper my-2 pl-2">
                         <span class="papertitle">Understanding the Role of Virtual Mobility on How and What People Create in Virtual Reality</span><br>
                         <span class="thisauthor">Eugy Han</span>, Portia Wang, Cyan DeVeaux, Gabriella M. Harari, and Jeremy N. Bailenson<br>
                         <i>Thinking Skills & Creativity</i>, 2025<br>

                         <a class="tag" href="assets/pdfs/han-tsc-2025.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
                         <a class="tag" href="https://www.sciencedirect.com/science/article/pii/S1871187124002372" target="_blank">website</a><span class="tagsep">|</span>
                         <a class="tag toggle-abstract" href="javascript:void(0);">nutshell description</a>
                     </p>

                     <div class="abstract-content">
                        <p>This article (1) looks at the role of virtual mobility on how/what people create in VR and (2) introduces a VR-specific creativity coding scheme based on prior literature. Key findings show that restricted movement leads to fewer deletions, fewer 3D models, shorter creations, and less practical designs.</p>
                    </div>

                    <br>

                    <p class="paper my-2 pl-2">
                     <span class="papertitle">How Different Training Types and Computer Anxiety Influence Performance and Experiences in Virtual Reality</span><br>
                     <span class="thisauthor">Eugy Han</span>, Ian Strate, Kristine L. Nowak, and Jeremy N. Bailenson<br>
                     <i>Media and Communication</i>, 2024<br>
                     <a class="tag" href="assets/pdfs/han-mac-2024.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
                     <a class="tag" href="https://www.cogitatiopress.com/mediaandcommunication/article/view/8730" target="_blank">website</a><span class="tagsep">|</span>
                     <a class="tag toggle-abstract" href="javascript:void(0);">nutshell description</a>
                 </p>
                 <div class="abstract-content">
                    <p>How do we best train people prior to VR? This article explores how different training methods (paper, video, VR) can help users better navigate VR experiences, and how these methods differ for those with tech anxiety. This study (<i>n</i>=284) found that video or direct VR training helped users master VR functions better than paper training + those who trained directly in VR had less of a negative experience using VR for completing tasks. However, tech anxiety played a role: those with high tech anxiety struggled more, regardless of training method. They found tasks harder, training less useful, and had a more negative experience overall.</p>
                </div>

                <br> 

                <p class="paper my-2 pl-2">
                    <span class="papertitle">Alone Together, Together Alone: The Effects of Social Context on Nonverbal Behavior in Virtual Reality</span><br>
                    <span class="thisauthor">Eugy Han</span>, Cyan DeVeaux, Mark Roman Miller, Gabriella M. Harari, Jeffrey T. Hancock, Nilam Ram, and Jeremy N. Bailenson<br>
                    <i>PRESENCE: Virtual and Augmented Reality</i>, 2024<br>
                    <a class="tag" href="assets/pdfs/han-presence-2024.pdf" target="_blank">pdf</a>
                    <span class="tagsep">|</span>
                    <a class="tag" href="https://direct.mit.edu/pvar/article-abstract/doi/10.1162/pres_a_00432/123565/Alone-Together-Together-Alone-The-Effects-of" target="_blank">website</a>
                    <span class="tagsep">|</span>
                    <a class="tag toggle-abstract" href="javascript:void(0);">nutshell description</a>
                </p>
                <div class="abstract-content">
                    <p>This 2-study article looks how the presence of other <i>virtual</i> people and <i>physical</i> people contextualize and influence nonverbal behaviors. Study 1 examines virtual context and looks at group interactions (<i>n</i>=104) while in a private (alone with group) or public (surrounded by multiple other groups) virtual environment. Results showed that participants moved their avatars slower and stood closer to group members in public versus private environments. <br><br>
                        Study 2 examines physical context and looks at group interactions (<i>n</i>=61) while people are physically alone/remote or together in a shared physical space. Results showed that, compared to remote participants, participants who were physically together moved their bodies more slowly, but their avatars faster. Moreover, there was more mutual gaze among remote participants.</p>
                    </div>

<!--                     <br>

                    <p class="paper my-2 pl-2">
                        <span class="papertitle">Presence and Pronouns: An Exploratory Investigation into the Language of Social VR</span><br>
                        Cyan DeVeaux, Dave M. Markowitz, <span class="thisauthor">Eugy Han</span>, Mark Roman Miller, Jeffrey T. Hancock, and Jeremy N. Bailenson<br>
                        <i>Journal of Language and Social Psychology</i>, 2024<br>
                        <a class="tag" href="assets/pdfs/deveaux-jlsp-2024.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
                        <a class="tag" href="https://journals.sagepub.com/doi/abs/10.1177/0261927X241248646" target="_blank">website</a><span class="tagsep">|</span>
                        <a class="tag toggle-abstract" href="javascript:void(0);">nutshell description</a>
                    </p>

                    <div class="abstract-content">
                        <p>This article looks at how people speak in social VR by analyzing 4,800 minutes of conversation, specifically looking at language patterns and how they tie to presence - the feeling of "being there." Key findings show that self-references and collective references correlate with higher social and spatial presence. Additionally, greater interpersonal distance was associated with more impersonal language.</p>
                    </div>

                    <br>  -->

                    <br>

                    <p class="paper my-2 pl-2">
                     <span class="papertitle">Lessons for/in Virtual Classrooms: Designing a Model for Classrooms inside Virtual Reality</span><br>
                     <span class="thisauthor">Eugy Han</span> and Jeremy N. Bailenson<br>
                     <i>Communication Education</i>, 2024<br>
                     <a class="tag" href="assets/pdfs/han-commed-2024.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
                     <a class="tag" href="https://www.tandfonline.com/doi/full/10.1080/03634523.2024.2312879" target="_blank">website</a><span class="tagsep">|</span>
                     <a class="tag" href="https://www.cnn.com/2022/01/27/tech/vr-classes/index.html" target="_blank">news coverage</a><span class="tagsep">|</span>
                     <a class="tag" href="https://news.stanford.edu/stories/2021/11/new-class-among-first-taught-entirely-virtual-reality" target="_blank">news coverage 2</a><span class="tagsep">|</span>
                     <a class="tag toggle-abstract" href="javascript:void(0);">nutshell description</a>
                 </p>

                 <div class="abstract-content">
                    <p>This article discusses the challenges + successes of integrating VR into classrooms through observations from the <i>Virtual People</i> course. Key insights include the need to acclimate students to VR, select appropriate tasks, manage technical issues, and plan both physical and virtual course configurations.</p>
                </div>


                <br> 

                <p class="paper my-2 pl-2">
                 <span class="papertitle">The Influence of Spatial Dimensions of Virtual Environments on Individuals and Group Dynamics During Social Interactions</span><br>
                 <span class="thisauthor">Eugy Han</span>, Cyan DeVeaux, Jeffrey T. Hancock, Nilam Ram, Gabriella M. Harari, and Jeremy N. Bailenson<br>
                 <i>Journal of Environmental Psychology</i>, 2024<br>
                 <a class="tag" href="assets/pdfs/han-jep-2024.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
                 <a class="tag" href="https://www.sciencedirect.com/science/article/pii/S0272494424000422" target="_blank">website</a><span class="tagsep">|</span>
                 <a class="tag toggle-abstract" href="javascript:void(0);">nutshell description</a>
             </p>

             <div class="abstract-content">
                <p>This article investigates how properties of the virtual room, namely ceiling height and floor size, shape people's attitudes and nonverbal behaviors during social interactions. Groups of 3-4 participants (<i>n</i>=110) used VR to have a discussion+engage in different activities in a virtual room that varied in ceiling height (low, high) and floor size (small, large) every week for four weeks. <br><br>

                    Results from self-report + motion (head, hands) data showed that virtual rooms with: High ceilings led to greater restorativeness, awe, momentary affective well-being + more social attention to other group members. Large floor areas led to greater sense of awe. High ceiling x large floor area led to slower physical head movement + greater interpersonal distance from other group members.
                </p>
            </div>


<!--             <br> 

            <p class="paper my-2 pl-2">
             <span class="papertitle">Seeing the world through digital prisms: Psychological implications of passthrough video usage in mixed reality</span><br>
             Jeremy N. Bailenson, Brian Beams, James Brown, Cyan DeVeaux, <span class="thisauthor">Eugy Han</span>, Anna C.M Queiroz, Rabindra Ratan, Monique Santoso, Tara Srirangarajan, Yujie Tao, and Portia Wang<br>
             <i>Technology, Mind, & Behavior</i>, 2024<br>
             <a class="tag" href="assets/pdfs/bailenson-tmb-2024.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
             <a class="tag" href="https://tmb.apaopen.org/pub/ztfn3ubj/release/1" target="_blank">website</a>
             <span class="tagsep">|</span>
             <a class="tag" href="https://www.newyorker.com/tech/annals-of-technology/where-will-virtual-reality-take-us" target="_blank">news coverage</a><span class="tagsep">|</span>
             <a class="tag" href="https://news.stanford.edu/2024/02/01/researchers-take-new-mixed-reality-headsets-spin/" target="_blank">news coverage 2</a><span class="tagsep">|</span>

             <a class="tag toggle-abstract" href="javascript:void(0);">nutshell description</a>
         </p>

         <div class="abstract-content">
            <p>This article examines the psychological effects of passthrough video in mixed reality (MR) headsets + highlights their growing role in media, technical limitations, and psychological impacts. While passthrough can inspire awe and enable new applications, it may also cause visual aftereffects, distance misjudgment, simulator sickness, and social disconnection.</p>
        </div>


        <br>  -->
<!-- 
        <p class="paper my-2 pl-2">
         <span class="papertitle">Understanding virtual design behaviors: A large-scale analysis of the design process in Virtual Reality</span><br>
         Portia Wang, Mark Roman Miller, <span class="thisauthor">Eugy Han</span>, and Jeremy N. Bailenson<br>
         <i>Design Studies</i>, 2024<br>
         <a class="tag" href="assets/pdfs/wang-designstudies-2024.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
         <a class="tag" href="https://www.sciencedirect.com/science/article/pii/S0142694X23000789" target="_blank">website</a>
         <span class="tagsep">|</span>
         <a class="tag toggle-abstract" href="javascript:void(0);">nutshell description</a>
     </p>

     <div class="abstract-content">
        <p>This article investigates the the design process in VR by extracting + analyzing behaviors of 254 students creating 730 designs. This article explores how these behaviors + virtual context inform final creations.</p>
    </div> -->

<!--     <br> 

    <p class="paper my-2 pl-2">
     <span class="papertitle">Exploring the Relationship Between Attribute Discrepancy and Avatar Embodiment in Immersive Social Virtual Reality</span><br>
     Cyan DeVeaux, <span class="thisauthor">Eugy Han</span>, James A. Landay, and Jeremy N. Bailenson<br>
     <i>Cyberpsychology, Behavior, and Social Networking</i>, 2023<br>
     <a class="tag" href="assets/pdfs/deveaux-cyberpsych-2023.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
     <a class="tag" href="https://www.liebertpub.com/doi/abs/10.1089/cyber.2023.0210" target="_blank">website</a>
     <span class="tagsep">|</span>
     <a class="tag toggle-abstract" href="javascript:void(0);">nutshell description</a>
 </p>

 <div class="abstract-content">
    <p>This article explores the role of visual proximity and discrepancy of one's avatar to their physical self + how this can impact different people differently. Discrepancy across 13 objective features (i.e., skin color, eye shape) reduced psychological connection between self and avatar. Asian participants showed particularly high discrepancy.</p>
</div>


<br>  -->
<br>

<p class="paper my-2 pl-2">
 <span class="papertitle">People, Places, and Time: A Large-scale, Longitudinal Study of Transformed Avatars and Environmental Context in Group Interaction in the Metaverse</span><br>
 <span class="thisauthor">Eugy Han</span>, Mark Roman Miller, Cyan Deveaux, Hanseul Jun, Kristine L. Nowak, Jeffrey T. Hancock, Nilam Ram, and Jeremy N. Bailenson<br>
 <i>Journal of Computer-Mediated Communication</i>, 2023<br>
 <a class="tag" href="assets/pdfs/han-jcmc-2023.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
 <a class="tag" href="https://tmb.apaopen.org/pub/xuyqf7l0/release/1" target="_blank">website</a>
 <span class="tagsep">|</span>
 <a class="tag" href="https://news.stanford.edu/stories/2022/12/vr-real-impact-study-finds" target="_blank">news coverage</a><span class="tagsep">|</span>
 <a class="tag" href="https://venturebeat.com/games/vr-study-shows-virtual-avatars-and-environments-can-affect-your-mood/" target="_blank">news coverage 2</a><span class="tagsep">|</span>
 <a class="tag toggle-abstract" href="javascript:void(0);">nutshell description</a>
</p>

<div class="abstract-content">
    <p><i>Who</i> you are and <i>where</i> you are matter during social interactions in VR. This 2-study article explores how avatar appearance (Study 1, <i>n</i>=81) and environmental contexts (Study 2, <i>n</i>=137) impact atttidues and behaviors, and how these evolve over time. Self-presence and realism increased over time in both studies. Avatars resembling participants increased nonverbal synchrony and realism but reduced enjoyment. As visible space increased, so did nonverbal synchrony, perceived restorativeness, entitativity, pleasure, arousal, self- and spatial presence, enjoyment, and realism. Outdoor environments increased perceived restorativeness and enjoyment more than indoor environments. 
    </p>
</div>

<br> 

<p class="paper my-2 pl-2">
 <span class="papertitle">Prerequisites for Learning in Networked Immersive Virtual Reality</span><br>
 <span class="thisauthor">Eugy Han</span>, Kristine L. Nowak, and Jeremy N. Bailenson<br>
 <i>Technology, Mind, & Behavior</i>, 2022<br>
 <a class="tag" href="assets/pdfs/han-tmb-2022.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
 <a class="tag" href="https://academic.oup.com/jcmc/article/28/2/zmac031/6972657?searchresult=1&login=true" target="_blank">website</a>
 <span class="tagsep">|</span>
 <a class="tag toggle-abstract" href="javascript:void(0);">nutshell description</a>
</p>

<div class="abstract-content">
    <p>There has been growing interest in using VR as a solution for many of the challenges facing distance education, such as fostering a sense of connectedness with classmates. However, implementing VR in distance education has its share of challenges, such as hardware accessibility and a scarcity of content which match curricula. This exploratory study presents observations on instructors' and students' experiences across time and with VR use. The key takeaway is: without learning how to use VR first, students cannot learn inside VR.</p>
</div>


<p class="header pt-5">Talks</p>
<div class="py-2">
 <p class="paper my-2 pl-2">
     <span class="papertitle">2025</span><br>
     Lab Tour for Professor Bayer (The Ohio State University)<br>
     Guest Lecture for ‚ÄúXR History, Theory, Impact‚Äù (Northeastern University)<br>
 </p>
 <br> 
 <p class="paper my-2 pl-2">
     <span class="papertitle">2024</span><br>
     Lab Tour for Vinnova (Swedish Innovation Agency)<br>
     Guest Lecture for ‚ÄúVirtual People‚Äù (Stanford University)<br>
     Talk for the Institute for Public Relations <br>
     Guest Lecture for ‚ÄúTechnology and Wellbeing‚Äù (Stanford University) <br>
     Talk and Demo for UC Berkeley/Belmont Village Retirees (UC Berkeley) <br>
     Talk at Metaverse and Education Conference (Lyc√©e Fran√ßais de New York) <br>
     Lab Tour for Professor Sandra Ponzanesi (Utrecht University) <br>
     Talk at University of Southern California (Institute of Creative Technologies) <br>
     Lab Tour for Professor Tamara Makana Chock (Syracuse University) <br>
     Mobile lab demo for California Academy of Sciences <br>
 </p>
 <br>
 <p class="paper my-2 pl-2">
     <span class="papertitle">2023</span><br>
     Lab Tour for Professor Misha Sra (UC Santa Barbara) <br>
     Guest Lecture at University of Florida (Digital Worlds Institute) <br>
     Mobile lab demo for eWear <br>
     Panel Guest at AWE USA Conference <br>
     Panel Guest at Stanford XR Conference <br>
     Lab Tour for Dr. Hubert Etienne (Meta) <br>
 </p>
 <br>
 <p class="paper my-2 pl-2">
     <span class="papertitle">2022</span><br>
     Talk at Quantum Photonics (ClubHouse) <br>
     Panel Guest at SALTISE Conference <br>
     Panel Guest at CODEX FutureLaw Conference <br>
     Guest Lecture at Universit√© Laval <br>
     Panel Guest at Bodyswaps: The Educators vs. Virtual Reality
 </p>
</div>

<br>

</div>

<footer class="text-center pt-4">
    <p>Last updated: <span id="last-updated"></span></p>
</footer>


<!-- <p class="header pt-5">In the News</p>
<div class="row text-center py-4">
    <div class="mx-auto mt-2">
        <img class="img-fluid instilogo p-1" src="images/mediaCover_theNewYorker.png">
        <div class="institution"><a class="tag" href="https://www.newyorker.com/tech/annals-of-technology/where-will-virtual-reality-take-us" target="_blank">The New Yorker</a></div>
        <div class="years">2024</div>
    </div>
    <div class="mx-auto mt-2">
        <img class="img-fluid instilogo p-1" src="images/mediaCover_stanfordNews.png">
        <div class="institution"><a class="tag" href="https://news.stanford.edu/2024/02/01/researchers-take-new-mixed-reality-headsets-spin/" target="_blank">Stanford News</a></div>
        <div class="years">2024</div>
    </div>
    <div class="mx-auto mt-2">
        <img class="img-fluid instilogo p-1" src="images/mediaCover_stanfordNews.png">
        <div class="institution"><a class="tag" href="https://news.stanford.edu/stories/2022/12/vr-real-impact-study-finds" target="_blank">Stanford News</a></div>
        <div class="years">2022</div>
    </div>
    <div class="mx-auto mt-2">
        <img class="img-fluid instilogo p-1" src="images/mediaCover_vb.png">
        <div class="institution"><a class="tag" href="https://venturebeat.com/games/vr-study-shows-virtual-avatars-and-environments-can-affect-your-mood/" target="_blank">VentureBeat</a></div>
        <div class="years">2022</div>
    </div>
    <div class="mx-auto mt-2">
        <img class="img-fluid instilogo p-1" src="images/mediaCover_CNN.png">
        <div class="institution"><a class="tag" href="https://www.cnn.com/2022/01/27/tech/vr-classes/index.html" target="_blank">CNN</a></div>
        <div class="years">2022</div>
    </div>
    <div class="mx-auto mt-2">
        <img class="img-fluid instilogo p-1" src="images/mediaCover_stanfordNews.png">
        <div class="institution"><a class="tag" href="https://news.stanford.edu/stories/2021/11/new-class-among-first-taught-entirely-virtual-reality" target="_blank">Stanford News</a></div>
        <div class="years">2021</div>
    </div>
</div> -->

</div>

</div>
</div>

<!-- Optional JavaScript -->
<!-- jQuery first, then Popper.js, then Bootstrap JS -->
<!--<script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script> -->
<!-- jQuery (Bootstrap depends on this) -->
<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>

<!-- Popper.js (needed for Bootstrap dropdowns & toggles) -->
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"></script>

<!-- Bootstrap JavaScript (enables toggling) -->
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"></script>

<!-- Custom JS -->
<script src="assets/style-3.js"></script>


<script>
    const lastModified = new Date(document.lastModified);
    const formattedDate = lastModified.toLocaleDateString("en-US", {
        year: "numeric",
        month: "long",
        day: "numeric"
    });
    document.getElementById("last-updated").textContent = formattedDate;
</script>
</body>
<style>
</style>
</html>